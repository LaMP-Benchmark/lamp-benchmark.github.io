---
layout: default
title: Related Papers | {{ site.name }}
permalink: papers
---

The following papers are related to the LaMP benchmark:



<ul>
   <li><a href="https://arxiv.org/abs/2304.11406">LaMP: When Large Language Models Meet Personalization</a></li>
   <li><a href="https://arxiv.org/abs/2506.00137">LaMP-QA: A Benchmark for Personalized Long-form Question Answering</a></li>
   <li><a href="https://arxiv.org/abs/2404.05970">Optimization Methods for Personalizing Large Language Models through Retrieval Augmentation</a></li>
   <li><a href="https://arxiv.org/abs/2409.09510">Comparing Retrieval-Augmentation and Parameter-Efficient Fine-Tuning for Privacy-Preserving Personalization of Large Language Models</a></li>
   <li><a href="https://arxiv.org/abs/2501.04167">Reasoning-Enhanced Self-Training for Long-Form Personalized Text Generation</a></li>
   <li><a href="https://arxiv.org/abs/2501.14956">ExPerT: Effective and Explainable Evaluation of Personalized Long-Form Text Generation</a></li>
   <li><a href="https://arxiv.org/abs/2508.10695">Learning from Natural Language Feedback for Personalized Question Answering</a></li>
   <li><a href="https://arxiv.org/abs/2509.19094">Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering</a></li>
</ul>



Feel free to explore these papers for more information on the LaMP benchmark.
